{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AxiomCUDA Usage Example\n",
    "\n",
    "This notebook demonstrates how to use **AxiomCUDA**, a GPU-accelerated implementation of the AXIOM (Active Inference agent) framework by VERSES Research.\n",
    "\n",
    "> **Credit**: Based on the original AXIOM work by VERSES Research (https://github.com/VersesTech/axiom)\n",
    "\n",
    "AxiomCUDA provides high-performance CUDA-accelerated tensor operations while maintaining the same API as the original AXIOM framework. This notebook covers:\n",
    "\n",
    "1. Setup and imports\n",
    "2. Environment initialization\n",
    "3. Model initialization (SMM, RMM, TMM, IMM)\n",
    "4. Running inference and planning\n",
    "5. Visualizing model states\n",
    "6. Running full episodes\n",
    "7. Analyzing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup and Imports\n",
    "\n",
    "First, we import the necessary modules from axiomcuda and check GPU availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core axiomcuda imports\n",
    "import axiomcuda\n",
    "from axiomcuda import visualize as vis\n",
    "from axiomcuda import infer as ax\n",
    "from axiomcuda.models import rmm as rmm_tools\n",
    "from axiomcuda.models import imm as imm_tools\n",
    "from axiomcuda.models import smm as smm_tools\n",
    "from axiomcuda.models import tmm as tmm_tools\n",
    "from axiomcuda import config as ax_config\n",
    "from axiomcuda import planner\n",
    "from axiomcuda.defaults import ExperimentConfig, create_smm_configs\n",
    "\n",
    "# JAX imports\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "# Other utilities\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Sequence\n",
    "\n",
    "# Environment\n",
    "import gymnasium\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA Available: {axiomcuda.cuda_available()}\")\n",
    "print(f\"JAX Devices: {jax.devices()}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "key = jr.PRNGKey(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Initialize Environment\n",
    "\n",
    "Create a Gameworld environment. AxiomCUDA works with Atari-like environments from the Gameworld suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gameworld environments (triggers registration)\n",
    "try:\n",
    "    import gameworld.envs\n",
    "    GAMEWORLD_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warning: gameworld package not available. Using mock environment.\")\n",
    "    GAMEWORLD_AVAILABLE = False\n",
    "\n",
    "if GAMEWORLD_AVAILABLE:\n",
    "    # Create environment\n",
    "    GAME_NAME = \"Explode\"\n",
    "    env = gymnasium.make(f'Gameworld-{GAME_NAME}-v0')\n",
    "    \n",
    "    # Reset environment to get initial observation\n",
    "    obs, info = env.reset(seed=SEED)\n",
    "    obs = obs.astype(np.uint8)\n",
    "    \n",
    "    print(f\"Environment: {GAME_NAME}\")\n",
    "    print(f\"Observation shape: {obs.shape}\")\n",
    "    print(f\"Action space: {env.action_space}\")\n",
    "    action_dim = env.action_space.n\n",
    "    print(f\"Number of actions: {action_dim}\")\n",
    "else:\n",
    "    # Mock environment for demonstration\n",
    "    print(\"Creating mock environment...\")\n",
    "    obs = np.random.randint(0, 255, (210, 160, 3), dtype=np.uint8)\n",
    "    action_dim = 4\n",
    "    env = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the initial observation\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.imshow(obs)\n",
    "ax.set_title(\"Initial Observation\")\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Initialize Models\n",
    "\n",
    "AxiomCUDA uses a modular architecture with four main models:\n",
    "\n",
    "- **SMM (Slot Mixture Model)**: Object discovery and segmentation\n",
    "- **TMM (Transition Mixture Model)**: Object dynamics and motion patterns\n",
    "- **RMM (Reward Mixture Model)**: Reward function and interaction modeling\n",
    "- **IMM (Identity Mixture Model)**: Object type identification\n",
    "\n",
    "Let's create configurations for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SMM configuration (Slot Mixture Model)\n",
    "smm_config = ax_config.SMMConfig(\n",
    "    width=160,\n",
    "    height=210,\n",
    "    input_dim=5,  # x, y, r, g, b\n",
    "    slot_dim=2,\n",
    "    num_slots=32,\n",
    "    use_bias=True,\n",
    "    ns_a=1.0,\n",
    "    ns_b=1.0,\n",
    "    dof_offset=10.0,\n",
    "    mask_prob=(0.0, 0.0, 0.0, 0.0, 1.0),\n",
    "    scale=(0.075, 0.075, 0.75, 0.75, 0.75),\n",
    "    transform_inv_v_scale=100.0,\n",
    "    bias_inv_v_scale=0.001,\n",
    "    num_e_steps=2,\n",
    "    learning_rate=1.0,\n",
    "    beta=0.0,\n",
    "    eloglike_threshold=5.0,\n",
    "    max_grow_steps=20,\n",
    ")\n",
    "print(\"SMM Configuration created\")\n",
    "print(f\"  - Number of slots: {smm_config.num_slots}\")\n",
    "print(f\"  - Input dimension: {smm_config.input_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TMM configuration (Transition Mixture Model)\n",
    "tmm_config = ax_config.TMMConfig(\n",
    "    n_total_components=200,\n",
    "    state_dim=2,\n",
    "    dt=1.0,\n",
    "    vu=0.05,\n",
    "    use_bias=True,\n",
    "    sigma_sqr=2.0,\n",
    "    logp_threshold=-0.00001,\n",
    "    position_threshold=0.15,\n",
    "    use_unused_counter=True,\n",
    "    use_velocity=True,\n",
    "    clip_value=5e-4,\n",
    ")\n",
    "print(\"TMM Configuration created\")\n",
    "print(f\"  - Total components: {tmm_config.n_total_components}\")\n",
    "print(f\"  - State dimension: {tmm_config.state_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IMM configuration (Identity Mixture Model)\n",
    "imm_config = ax_config.IMMConfig(\n",
    "    num_object_types=32,\n",
    "    num_features=5,\n",
    "    i_ell_threshold=-500.0,\n",
    "    cont_scale_identity=0.5,\n",
    "    color_precision_scale=1.0,\n",
    "    color_only_identity=False,\n",
    ")\n",
    "print(\"IMM Configuration created\")\n",
    "print(f\"  - Number of object types: {imm_config.num_object_types}\")\n",
    "print(f\"  - Number of features: {imm_config.num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RMM configuration (Reward Mixture Model)\n",
    "rmm_config = ax_config.RMMConfig(\n",
    "    num_components_per_switch=25,\n",
    "    num_switches=100,\n",
    "    num_object_types=32,\n",
    "    num_features=5,\n",
    "    num_continuous_dims=7,\n",
    "    interact_with_static=False,\n",
    "    r_ell_threshold=-100.0,\n",
    "    i_ell_threshold=-500.0,\n",
    "    cont_scale_identity=0.5,\n",
    "    cont_scale_switch=25.0,\n",
    "    discrete_alphas=(1e-4, 1e-4, 1e-4, 1e-4, 1.0, 1e-4),\n",
    "    r_interacting=0.6,\n",
    "    r_interacting_predict=0.6,\n",
    "    forward_predict=False,\n",
    "    stable_r=False,\n",
    "    relative_distance=True,\n",
    "    absolute_distance_scale=False,\n",
    "    reward_prob_threshold=0.45,\n",
    "    color_precision_scale=1.0,\n",
    "    color_only_identity=False,\n",
    "    exclude_background=True,\n",
    "    use_ellipses_for_interaction=True,\n",
    "    velocity_scale=10.0,\n",
    ")\n",
    "print(\"RMM Configuration created\")\n",
    "print(f\"  - Components per switch: {rmm_config.num_components_per_switch}\")\n",
    "print(f\"  - Number of switches: {rmm_config.num_switches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Planner configuration (MPPI)\n",
    "planner_config = ax_config.PlannerConfig(\n",
    "    num_steps=24,        # Planning horizon\n",
    "    num_policies=512,    # Number of action sequences to sample\n",
    "    num_samples_per_policy=1,\n",
    "    topk_ratio=0.1,      # Fraction of top samples for refitting\n",
    "    random_ratio=0.5,    # Fraction of random samples\n",
    "    alpha=1.0,           # Learning rate\n",
    "    temperature=10.0,    # Temperature for softmax\n",
    "    normalize=True,\n",
    "    iters=1,\n",
    "    gamma=0.99,          # Discount factor\n",
    "    repeat_prob=0.0,\n",
    "    info_gain=1.0,       # Weight for information gain\n",
    "    lazy_reward=False,\n",
    "    sample_action=False,\n",
    ")\n",
    "print(\"Planner Configuration created\")\n",
    "print(f\"  - Planning horizon: {planner_config.num_steps}\")\n",
    "print(f\"  - Number of policies: {planner_config.num_policies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the full experiment configuration\n",
    "config = ExperimentConfig(\n",
    "    name=\"axiomcuda_demo\",\n",
    "    id=\"demo_001\",\n",
    "    group=\"demo\",\n",
    "    seed=SEED,\n",
    "    game=\"Explode\" if env is not None else \"Mock\",\n",
    "    num_steps=1000,\n",
    "    smm=(smm_config,),  # Tuple of SMM configs (can be multiple for hierarchical)\n",
    "    imm=imm_config,\n",
    "    tmm=tmm_config,\n",
    "    rmm=rmm_config,\n",
    "    planner=planner_config,\n",
    "    moving_threshold=1e-2,\n",
    "    used_threshold=0.2,\n",
    "    min_track_steps=(1, 1),\n",
    "    max_steps_tracked_unused=10,\n",
    "    prune_every=500,\n",
    "    use_unused_counter=True,\n",
    "    project=\"axiomcuda\",\n",
    "    precision_type=\"float32\",\n",
    "    layer_for_dynamics=0,\n",
    "    warmup_smm=False,\n",
    "    num_warmup_steps=50,\n",
    "    velocity_clip_value=7.5e-4,\n",
    "    bmr_samples=2000,\n",
    "    bmr_pairs=2000,\n",
    ")\n",
    "\n",
    "print(\"Experiment Configuration created successfully!\")\n",
    "print(f\"\\nConfiguration Summary:\")\n",
    "print(f\"  - Experiment name: {config.name}\")\n",
    "print(f\"  - Game: {config.game}\")\n",
    "print(f\"  - Seed: {config.seed}\")\n",
    "print(f\"  - Number of steps: {config.num_steps}\")\n",
    "print(f\"  - Number of SMM layers: {len(config.smm) if isinstance(config.smm, Sequence) else 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all models using axiomcuda.init\n",
    "# This creates the initial carry dictionary containing all model states\n",
    "\n",
    "key, subkey = jr.split(key)\n",
    "carry = ax.init(subkey, config, obs, action_dim)\n",
    "\n",
    "print(\"Models initialized successfully!\")\n",
    "print(f\"\\nCarry dictionary keys:\")\n",
    "for key_name in carry.keys():\n",
    "    print(f\"  - {key_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the structure of each model\n",
    "print(\"SMM Model Structure:\")\n",
    "print(f\"  - Type: {type(carry['smm_model'])}\")\n",
    "if hasattr(carry['smm_model'], 'stats'):\n",
    "    print(f\"  - Stats keys: {list(carry['smm_model'].stats.keys())}\")\n",
    "\n",
    "print(\"\\nTMM Model Structure:\")\n",
    "print(f\"  - Type: {type(carry['tmm_model'])}\")\n",
    "\n",
    "print(\"\\nRMM Model Structure:\")\n",
    "print(f\"  - Type: {type(carry['rmm_model'])}\")\n",
    "if hasattr(carry['rmm_model'], 'used_mask'):\n",
    "    print(f\"  - Used components: {carry['rmm_model'].used_mask.sum()}\")\n",
    "\n",
    "print(\"\\nIMM Model Structure:\")\n",
    "print(f\"  - Type: {type(carry['imm_model'])}\")\n",
    "if hasattr(carry['imm_model'], 'used_mask'):\n",
    "    print(f\"  - Used identities: {carry['imm_model'].used_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Run Inference\n",
    "\n",
    "Now let's run a single step through the environment to see how the models work together:\n",
    "\n",
    "1. **Plan**: Use MPPI to select an action\n",
    "2. **Step**: Execute the action in the environment\n",
    "3. **Update**: Update models with the new observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Plan action using MPPI (Model Predictive Path Integral)\n",
    "key, subkey = jr.split(key)\n",
    "action, carry, plan_info = ax.plan_fn(subkey, carry, config, action_dim)\n",
    "\n",
    "print(f\"Planned action: {action}\")\n",
    "print(f\"\\nPlanning info keys: {list(plan_info.keys())}\")\n",
    "\n",
    "# Inspect plan info\n",
    "if 'rewards' in plan_info:\n",
    "    print(f\"\\nRewards shape: {plan_info['rewards'].shape}\")\n",
    "    print(f\"Expected utility shape: {plan_info['expected_utility'].shape}\")\n",
    "    print(f\"Expected info gain shape: {plan_info['expected_info_gain'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Execute action in environment\n",
    "if env is not None:\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    obs = obs.astype(np.uint8)\n",
    "else:\n",
    "    # Mock step\n",
    "    obs = np.random.randint(0, 255, (210, 160, 3), dtype=np.uint8)\n",
    "    reward = np.random.randn()\n",
    "    done = False\n",
    "\n",
    "print(f\"Step result:\")\n",
    "print(f\"  - Action taken: {action}\")\n",
    "print(f\"  - Reward received: {reward:.4f}\")\n",
    "print(f\"  - Episode done: {done}\")\n",
    "print(f\"  - New observation shape: {obs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Update models with the new observation\n",
    "carry, records = ax.step_fn(\n",
    "    carry,\n",
    "    config,\n",
    "    obs,\n",
    "    jnp.array(reward),\n",
    "    action,\n",
    "    num_tracked=0,\n",
    "    update=True,\n",
    "    remap_color=False,\n",
    ")\n",
    "\n",
    "print(\"Models updated successfully!\")\n",
    "print(f\"\\nRecords keys: {list(records.keys())}\")\n",
    "\n",
    "# Inspect the records\n",
    "if 'decoded_mu' in records:\n",
    "    print(f\"\\nDecoded means shape: {records['decoded_mu'][0].shape}\")\n",
    "if 'switches' in records:\n",
    "    print(f\"TMM switches: {records['switches']}\")\n",
    "if 'rmm_switches' in records:\n",
    "    print(f\"RMM switches: {records['rmm_switches']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Visualize Models\n",
    "\n",
    "Let's visualize the internal state of each model after the first update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RMM (Reward Mixture Model)\n",
    "# The RMM components represent learned reward functions and interactions\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "# Color by different attributes\n",
    "colorize_options = ['switch', 'reward', 'cluster', 'infogain']\n",
    "\n",
    "for idx, colorize in enumerate(colorize_options):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    try:\n",
    "        # Get the plot\n",
    "        rmm_img = vis.plot_rmm(\n",
    "            carry['rmm_model'], \n",
    "            carry['imm_model'],\n",
    "            colorize=colorize,\n",
    "            return_ax=False\n",
    "        )\n",
    "        ax.imshow(rmm_img)\n",
    "        ax.set_title(f'RMM - Colored by {colorize}')\n",
    "        ax.axis('off')\n",
    "    except Exception as e:\n",
    "        ax.text(0.5, 0.5, f'Error: {str(e)}', ha='center', va='center')\n",
    "        ax.set_title(f'RMM - {colorize} (Error)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('RMM State Visualization', fontsize=16, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"Colorization options:\")\n",
    "print(\"  - switch: Components colored by TMM switch assignment\")\n",
    "print(\"  - reward: Components colored by reward value (red=negative, green=positive)\")\n",
    "print(\"  - cluster: Components colored by identity\")\n",
    "print(\"  - infogain: Components colored by information gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SMM slots\n",
    "# SMM performs object discovery and segmentation\n",
    "\n",
    "if 'decoded_mu' in records and 'decoded_sigma' in records:\n",
    "    smm_img = vis.plot_smm(\n",
    "        records['decoded_mu'][0],\n",
    "        records['decoded_sigma'][0],\n",
    "        carry['smm_model'].stats['offset'],\n",
    "        carry['smm_model'].stats['stdevs'],\n",
    "        width=160,\n",
    "        height=210,\n",
    "        qz=records['qz'][0] if 'qz' in records else None\n",
    "    )\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.imshow(smm_img)\n",
    "    ax.set_title('SMM Slot Visualization')\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Number of slots: {len(records['decoded_mu'][0])}\")\n",
    "    print(f\"Each ellipse represents a discovered object/slot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the planning results\n",
    "# Shows the top-k trajectories considered by MPPI\n",
    "\n",
    "if env is not None:\n",
    "    try:\n",
    "        plan_img = vis.plot_plan(\n",
    "            obs,\n",
    "            plan_info,\n",
    "            carry['tracked_obj_ids'][config.layer_for_dynamics],\n",
    "            carry['smm_model'].stats,\n",
    "            decoded_mu=records['decoded_mu'][0] if 'decoded_mu' in records else None,\n",
    "            topk=5\n",
    "        )\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.imshow(plan_img)\n",
    "        ax.set_title('MPPI Planning Visualization')\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"The visualization shows:\")\n",
    "        print(\"  - Current observation as background\")\n",
    "        print(\"  - Top-5 planned trajectories overlaid\")\n",
    "        print(\"  - Trajectories colored by expected reward\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting plan: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Identity Model (IMM)\n",
    "# IMM learns to identify object types based on their visual features\n",
    "\n",
    "try:\n",
    "    imm_img = vis.plot_identity_model(\n",
    "        carry['imm_model'],\n",
    "        color_only_identity=imm_config.color_only_identity\n",
    "    )\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.imshow(imm_img)\n",
    "    ax.set_title('IMM - Learned Object Identities')\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Each subplot shows a learned object identity:\")\n",
    "    print(\"  - Ellipse shows shape and size\")\n",
    "    print(\"  - Color shows learned RGB values\")\n",
    "    print(\"  - Title indicates if this identity is active (True/False)\")\n",
    "except Exception as e:\n",
    "    print(f\"Error plotting IMM: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize TMM (Transition Mixture Model) components\n",
    "# TMM models different motion patterns (static, constant velocity, etc.)\n",
    "\n",
    "if hasattr(carry['tmm_model'], 'transitions'):\n",
    "    try:\n",
    "        tmm_img = vis.plot_tmm(\n",
    "            carry['tmm_model'].transitions,\n",
    "            carry['tmm_model'].used_mask,\n",
    "            width=160,\n",
    "            height=210\n",
    "        )\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax.imshow(tmm_img)\n",
    "        ax.set_title('TMM - Transition Components')\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        used_components = int(carry['tmm_model'].used_mask.sum())\n",
    "        print(f\"Total TMM components: {len(carry['tmm_model'].transitions)}\")\n",
    "        print(f\"Used components: {used_components}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting TMM: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Run Episode\n",
    "\n",
    "Now let's run a full episode (multiple steps) to see how the agent learns over time.\n",
    "We'll track:\n",
    "- Rewards collected\n",
    "- Model component growth\n",
    "- Generate a video of the gameplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset environment for a fresh episode\n",
    "if env is not None:\n",
    "    obs, _ = env.reset(seed=SEED)\n",
    "    obs = obs.astype(np.uint8)\n",
    "else:\n",
    "    obs = np.random.randint(0, 255, (210, 160, 3), dtype=np.uint8)\n",
    "\n",
    "# Re-initialize models\n",
    "key, subkey = jr.split(key)\n",
    "carry = ax.init(subkey, config, obs, action_dim)\n",
    "\n",
    "print(\"Environment reset and models re-initialized\")\n",
    "print(f\"Starting new episode...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run episode for N steps\n",
    "N_STEPS = 100  # Number of steps to run\n",
    "\n",
    "# Data collection arrays\n",
    "observations = [obs]\n",
    "rewards_list = []\n",
    "actions_list = []\n",
    "component_counts = []\n",
    "expected_utilities = []\n",
    "expected_info_gains = []\n",
    "\n",
    "print(f\"Running {N_STEPS} steps...\")\n",
    "\n",
    "for step in range(N_STEPS):\n",
    "    # Plan action\n",
    "    key, subkey = jr.split(key)\n",
    "    action, carry, plan_info = ax.plan_fn(subkey, carry, config, action_dim)\n",
    "    \n",
    "    # Track planning metrics\n",
    "    if 'rewards' in plan_info:\n",
    "        best_idx = jnp.argsort(plan_info['rewards'][:, :, 0].sum(0))[-1]\n",
    "        expected_utilities.append(\n",
    "            float(plan_info['expected_utility'][:, best_idx, :].mean(-1).sum(0))\n",
    "        )\n",
    "        expected_info_gains.append(\n",
    "            float(plan_info['expected_info_gain'][:, best_idx, :].mean(-1).sum(0))\n",
    "        )\n",
    "    \n",
    "    # Track RMM component count\n",
    "    if hasattr(carry['rmm_model'], 'used_mask'):\n",
    "        component_counts.append(int(carry['rmm_model'].used_mask.sum()))\n",
    "    \n",
    "    # Execute action\n",
    "    if env is not None:\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        obs = obs.astype(np.uint8)\n",
    "    else:\n",
    "        obs = np.random.randint(0, 255, (210, 160, 3), dtype=np.uint8)\n",
    "        reward = np.random.randn()\n",
    "        done = False\n",
    "    \n",
    "    # Store data\n",
    "    observations.append(obs)\n",
    "    rewards_list.append(float(reward))\n",
    "    actions_list.append(int(action))\n",
    "    \n",
    "    # Update models\n",
    "    carry, records = ax.step_fn(\n",
    "        carry,\n",
    "        config,\n",
    "        obs,\n",
    "        jnp.array(reward),\n",
    "        action,\n",
    "        num_tracked=0,\n",
    "        update=True,\n",
    "        remap_color=False,\n",
    "    )\n",
    "    \n",
    "    # Progress update every 25 steps\n",
    "    if (step + 1) % 25 == 0:\n",
    "        recent_reward = np.mean(rewards_list[-25:])\n",
    "        recent_components = np.mean(component_counts[-25:]) if component_counts else 0\n",
    "        print(f\"Step {step+1}/{N_STEPS}: \"\n",
    "              f\"Avg reward (last 25): {recent_reward:.3f}, \"\n",
    "              f\"Avg components: {recent_components:.1f}\")\n",
    "    \n",
    "    if done:\n",
    "        print(f\"Episode done at step {step+1}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nEpisode complete! Total steps: {len(rewards_list)}\")\n",
    "print(f\"Total reward: {sum(rewards_list):.2f}\")\n",
    "print(f\"Average reward per step: {np.mean(rewards_list):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate video from observations\n",
    "try:\n",
    "    import mediapy\n",
    "    \n",
    "    # Show video\n",
    "    print(\"Generating gameplay video...\")\n",
    "    mediapy.show_video(observations, fps=30, title=\"AxiomCUDA Gameplay\")\n",
    "except ImportError:\n",
    "    print(\"mediapy not available. Showing first few frames instead:\")\n",
    "    \n",
    "    # Show first 4 frames\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx < len(observations):\n",
    "            ax.imshow(observations[idx])\n",
    "            ax.set_title(f'Frame {idx}')\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Analyze Results\n",
    "\n",
    "Let's analyze what the agent learned during the episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reward curve\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Reward over time\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(rewards_list, alpha=0.5, color='blue', label='Step reward')\n",
    "# Add moving average\n",
    "window = min(25, len(rewards_list) // 4 + 1)\n",
    "if window > 1:\n",
    "    moving_avg = np.convolve(rewards_list, np.ones(window)/window, mode='valid')\n",
    "    ax1.plot(range(window-1, len(rewards_list)), moving_avg, \n",
    "             color='red', linewidth=2, label=f'{window}-step MA')\n",
    "ax1.set_xlabel('Step')\n",
    "ax1.set_ylabel('Reward')\n",
    "ax1.set_title('Reward Curve')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Cumulative reward\n",
    "ax2 = axes[0, 1]\n",
    "cumulative_rewards = np.cumsum(rewards_list)\n",
    "ax2.plot(cumulative_rewards, color='green')\n",
    "ax2.set_xlabel('Step')\n",
    "ax2.set_ylabel('Cumulative Reward')\n",
    "ax2.set_title('Cumulative Reward Over Time')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Component count over time\n",
    "if component_counts:\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.plot(component_counts, color='purple')\n",
    "    ax3.set_xlabel('Step')\n",
    "    ax3.set_ylabel('RMM Components')\n",
    "    ax3.set_title('Model Growth: RMM Components')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Component growth rate\n",
    "    ax4 = axes[1, 1]\n",
    "    if len(component_counts) > 1:\n",
    "        growth = np.diff(component_counts)\n",
    "        ax4.bar(range(len(growth)), growth, alpha=0.7, color='orange')\n",
    "        ax4.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "        ax4.set_xlabel('Step')\n",
    "        ax4.set_ylabel('Component Change')\n",
    "        ax4.set_title('Component Growth Rate')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Episode Analysis', fontsize=16, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nEpisode Statistics:\")\n",
    "print(f\"  - Total steps: {len(rewards_list)}\")\n",
    "print(f\"  - Total reward: {sum(rewards_list):.2f}\")\n",
    "print(f\"  - Mean reward: {np.mean(rewards_list):.3f} Â± {np.std(rewards_list):.3f}\")\n",
    "print(f\"  - Max reward: {max(rewards_list):.2f}\")\n",
    "print(f\"  - Min reward: {min(rewards_list):.2f}\")\n",
    "if component_counts:\n",
    "    print(f\"  - Final components: {component_counts[-1]}\")\n",
    "    print(f\"  - Component growth: {component_counts[-1] - component_counts[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot planning metrics\n",
    "if expected_utilities and expected_info_gains:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Expected utility\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(expected_utilities, color='blue', alpha=0.7)\n",
    "    ax1.set_xlabel('Step')\n",
    "    ax1.set_ylabel('Expected Utility')\n",
    "    ax1.set_title('MPPI Expected Utility Over Time')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Expected information gain\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(expected_info_gains, color='red', alpha=0.7)\n",
    "    ax2.set_xlabel('Step')\n",
    "    ax2.set_ylabel('Expected Info Gain')\n",
    "    ax2.set_title('MPPI Expected Information Gain Over Time')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nPlanning Statistics:\")\n",
    "    print(f\"  - Mean expected utility: {np.mean(expected_utilities):.3f}\")\n",
    "    print(f\"  - Mean expected info gain: {np.mean(expected_info_gains):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show final model states\n",
    "print(\"Final Model States:\\n\")\n",
    "\n",
    "# RMM state\n",
    "print(\"RMM (Reward Mixture Model):\")\n",
    "if hasattr(carry['rmm_model'], 'used_mask'):\n",
    "    used = carry['rmm_model'].used_mask.sum()\n",
    "    total = len(carry['rmm_model'].used_mask)\n",
    "    print(f\"  - Used components: {used}/{total} ({100*used/total:.1f}%)\")\n",
    "\n",
    "# IMM state\n",
    "print(\"\\nIMM (Identity Mixture Model):\")\n",
    "if hasattr(carry['imm_model'], 'used_mask'):\n",
    "    used = carry['imm_model'].used_mask.sum()\n",
    "    total = len(carry['imm_model'].used_mask)\n",
    "    print(f\"  - Used identities: {used}/{total} ({100*used/total:.1f}%)\")\n",
    "\n",
    "# TMM state\n",
    "print(\"\\nTMM (Transition Mixture Model):\")\n",
    "if hasattr(carry['tmm_model'], 'used_mask'):\n",
    "    used = carry['tmm_model'].used_mask.sum()\n",
    "    total = len(carry['tmm_model'].used_mask)\n",
    "    print(f\"  - Used transitions: {used}/{total} ({100*used/total:.1f}%)\")\n",
    "\n",
    "# SMM state\n",
    "print(\"\\nSMM (Slot Mixture Model):\")\n",
    "if hasattr(carry['smm_model'], 'stats'):\n",
    "    print(f\"  - Image dimensions: {carry['smm_model'].stats.get('width', 'N/A')}x{carry['smm_model'].stats.get('height', 'N/A')}\")\n",
    "if hasattr(carry['smm_model'], 'prior'):\n",
    "    print(f\"  - Number of slots: {len(carry['smm_model'].prior.alpha)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# 1. RMM with cluster coloring\n",
    "try:\n",
    "    rmm_img = vis.plot_rmm(\n",
    "        carry['rmm_model'], \n",
    "        carry['imm_model'],\n",
    "        colorize='cluster',\n",
    "        return_ax=False\n",
    "    )\n",
    "    axes[0, 0].imshow(rmm_img)\n",
    "    axes[0, 0].set_title('Final RMM State (Colored by Identity)')\n",
    "    axes[0, 0].axis('off')\n",
    "except Exception as e:\n",
    "    axes[0, 0].text(0.5, 0.5, f'Error: {str(e)}', ha='center', va='center')\n",
    "    axes[0, 0].set_title('RMM (Error)')\n",
    "\n",
    "# 2. IMM\n",
    "try:\n",
    "    imm_img = vis.plot_identity_model(carry['imm_model'])\n",
    "    axes[0, 1].imshow(imm_img)\n",
    "    axes[0, 1].set_title('Final IMM State')\n",
    "    axes[0, 1].axis('off')\n",
    "except Exception as e:\n",
    "    axes[0, 1].text(0.5, 0.5, f'Error: {str(e)}', ha='center', va='center')\n",
    "    axes[0, 1].set_title('IMM (Error)')\n",
    "\n",
    "# 3. Last observation\n",
    "axes[1, 0].imshow(observations[-1])\n",
    "axes[1, 0].set_title('Final Observation')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# 4. Action distribution\n",
    "unique_actions, counts = np.unique(actions_list, return_counts=True)\n",
    "axes[1, 1].bar(unique_actions, counts, alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Action')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].set_title('Action Distribution')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Final State Summary', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated the core functionality of AxiomCUDA:\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **SMM (Slot Mixture Model)**: Discovers objects by learning slot-based representations\n",
    "2. **TMM (Transition Mixture Model)**: Learns object dynamics and motion patterns\n",
    "3. **RMM (Reward Mixture Model)**: Models rewards and object interactions\n",
    "4. **IMM (Identity Mixture Model)**: Identifies object types from visual features\n",
    "\n",
    "### Key Functions\n",
    "\n",
    "- `ax.init()`: Initialize all models\n",
    "- `ax.plan_fn()`: Plan actions using MPPI\n",
    "- `ax.step_fn()`: Update models with new observations\n",
    "- `ax.reduce_fn_rmm()`: Bayesian Model Reduction for component pruning\n",
    "\n",
    "### Visualization Functions\n",
    "\n",
    "- `vis.plot_rmm()`: Visualize reward model components\n",
    "- `vis.plot_smm()`: Visualize slot assignments\n",
    "- `vis.plot_identity_model()`: Visualize learned object identities\n",
    "- `vis.plot_plan()`: Visualize planning trajectories\n",
    "- `vis.plot_tmm()`: Visualize transition dynamics\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "- Original AXIOM paper: https://github.com/VersesTech/axiom\n",
    "- Active Inference framework\n",
    "- Model Predictive Path Integral (MPPI) control\n",
    "\n",
    "---\n",
    "\n",
    "**Credits**: This notebook is based on the AXIOM framework by VERSES Research. AxiomCUDA provides a GPU-accelerated implementation while maintaining API compatibility with the original framework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}